from typing import List
import re
import json
import os
import datetime
from collections import defaultdict

from gtts import gTTS
from requests_html import HTMLSession
from bs4 import BeautifulSoup
from pydantic import BaseModel, Field
from warnings import filterwarnings

import torch
from diffusers import DiffusionPipeline

from langchain_core.tools import tool
from langchain_ollama.chat_models import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.tools import DuckDuckGoSearchResults

from moviepy import ImageClip, AudioFileClip, concatenate_videoclips

from config import CONFIG

try:
    from langchain_core._api.deprecation import LangChainDeprecationWarning
    filterwarnings("ignore", category=LangChainDeprecationWarning)
except ImportError:
    filterwarnings("ignore", message="LangChainDeprecationWarning")


class ScriptSection(BaseModel):
    section_number: int = Field(..., description="The number of the section in the video")
    section_title: str = Field(..., description="The title of the section")
    narration: str = Field(..., description="The narration of the section")
    prompt_for_image: List[str] = Field(..., description="The prompt for the image")


class VideoScript(BaseModel):
    project_name: str = Field(..., description="The name of the project")
    title: str = Field(..., description="The title of the video")
    description: str = Field(..., description="The description of the video")
    script_sections: List[ScriptSection] = Field(..., description="The sections of the video")


@tool   
def generate_video_script(user_prompt: str) -> str:
    """This tool produces a structured response and stores it in the appropriate directory.
    The ouput follows the VideoScript schema with project_name, title, description, and script_sections.
    
    :param user_prompt: The prompt to generate the video script from.
    :return: A path to the json file containing the structured video script ready for image generation.
    """
    
    output_dir = "projects"
    os.makedirs(output_dir, exist_ok=True)
    
    model_config = CONFIG["llm_model_config"]
    prompt_config = CONFIG["llm_prompt_config"]
    
    model = ChatOllama(
        model = model_config["model_name"],
        temperature = model_config["temperature"],
        num_ctx = model_config["num_ctx"],
    )
            
    USER_PROMPT = f"""Generate a video script for the following prompt:
    {user_prompt}

    # Example
    User Prompt: 
    "History of football"
    
    Output:
    {prompt_config["example_prompt"]}
    """
    
    messages = [
        SystemMessage(content=[{"type": "text", "text": prompt_config["system_prompt"]}]),
        HumanMessage(content=[{"type": "text", "text": USER_PROMPT}]),
    ]
    
    max_retries = 3
    retry_count = 0
    while retry_count < max_retries:
        try:
            structured_output = model.with_structured_output(VideoScript)
            response = structured_output.invoke(messages)
            json_response = response.model_dump()
            print(f"Video script generated successfully")
            break
        except Exception as e:
            print(f"Error in generating video script: {e}, retrying...")
            retry_count += 1
            continue

    timestamp = datetime.datetime.now().strftime("%d_%H_%M")
    filename = f"llm_response_{timestamp}.json"
    
    project_dir = os.path.join(output_dir, json_response["project_name"])
    os.makedirs(project_dir, exist_ok=True)
    output_path = os.path.join(project_dir, filename)

    with open(output_path, "w") as f:
        json.dump(json_response, f)
    
    return output_path


@tool
def generate_visuals(output_path: str) -> str:
    """This tool generates images from the video script generated by generate_video_script().
    
    This tool takes the project directory from generate_video_script() and creates images for each
    section based on the prompt suggestions included in the script.

    The only task is to pass the json response from generate_video_script() to this function and it will save the images to the project directory.
    
    :param output_path: The path to the json file containing the structured script
    :return: str (path to the project directory where images are saved)
    """
    
    project_dir = os.path.dirname(output_path)

    with open(output_path, "r") as f:
        video_script = json.load(f)

    model_id = CONFIG["image_generation_config"]["model_name"]
    num_inference_steps = CONFIG["image_generation_config"]["num_inference_steps"]
    guidance_scale = CONFIG["image_generation_config"]["guidance_scale"]

    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    pipe = DiffusionPipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True
    )

    pipe = pipe.to(device)
    image_dir = os.path.join(project_dir, "images")
    
    os.makedirs(image_dir, exist_ok=True)

    for section in video_script["script_sections"]:
        section_number = section["section_number"]
        print(f"Generating images for section {section_number}")

        for index, prompt in enumerate(section["prompt_for_image"]):
            max_retries = 2
            retry_count = 0
            while retry_count < max_retries:
                try:
                    image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]
                    image.save(os.path.join(image_dir, f"section_{section_number}_image_{index + 1}.png"))
                    break
                except Exception as e:
                    print(f"Error generating image for section {section_number}, image {index + 1}: {e}")
                    retry_count += 1
                    if retry_count == max_retries:
                        print(f"Failed to generate image after {max_retries} attempts")
                    continue
    
    return image_dir


@tool
def generate_audio_from_script(script_path: str) -> str:
    """This tool generates audio files from a video script generated by generate_video_script().
    
    This tool takes the output path from generate_video_script() and creates audio files for each
    section of the script using text-to-speech.
    
    :param script_path: The path to the json file containing the structured script
    :return: str (path to the project directory where audio files are saved)
    """

    project_dir = os.path.dirname(script_path)

    audio_dir = os.path.join(project_dir, "audio")
    os.makedirs(audio_dir, exist_ok=True)
    
    with open(script_path, "r") as f:
        video_script = json.load(f)
    
    audio_paths = []
    
    for section in video_script["script_sections"]:
        print(f"Generating audio for section {section['section_number']}")

        section_number = section["section_number"]
        narration = section["narration"]
        
        output_path = os.path.join(audio_dir, f"{video_script['project_name']}_section_{section_number}.mp3")
        
        tts = gTTS(text=narration, lang="en", slow=False)
        tts.save(output_path)
        
        audio_paths.append(output_path)

    return audio_dir


@tool(return_direct=True)
def assemble_video(project_dir: str) -> str | None:
    """
    Assembles a video by pairing images with corresponding audio clips and outputs the final video.
    For each section, there may be multiple images that should be shown during the audio of that section.
    The audio duration is split evenly among all images belonging to the same section.
    
    :param project_dir: The directory of the project
    :return: str: Path to the output video file
    """

    image_dir = os.path.join(project_dir, "images")
    audio_dir = os.path.join(project_dir, "audio")

    image_clips = []
    
    images = sorted(os.listdir(image_dir))
    audio_files = sorted(os.listdir(audio_dir))
        
    section_images = defaultdict(list)
    for image in images:
        match = re.search(r'section_(\d+)', image)
        if match:
            section_num = match.group(1)
            section_images[section_num].append(image)
    
    section_numbers = sorted(section_images.keys(), key=int)
    
    section_audios = {}
    for audio_file in audio_files:
        match = re.search(r'section_(\d+)', audio_file)
        if match:
            section_num = match.group(1)
            section_audios[section_num] = audio_file
    
    output_path = os.path.join(project_dir, "video.mp4")
    
    for section_num in section_numbers:
        section_images_list = section_images[section_num]
        audio_file = section_audios.get(section_num)
        
        if not audio_file:
            print(f"Warning: No audio file found for section {section_num}")
            continue
            
        
        audio_path = os.path.join(audio_dir, audio_file)
        audio_clip = AudioFileClip(audio_path)
        total_duration = audio_clip.duration
        
        image_duration = total_duration / len(section_images_list)
        
        section_clips = []
        for i, image_file in enumerate(section_images_list):
            image_path = os.path.join(image_dir, image_file)
            
            start_time = i * image_duration
            end_time = (i + 1) * image_duration if i < len(section_images_list) - 1 else total_duration
            
            image_clip = ImageClip(image_path).with_duration(end_time - start_time)
            
            audio_segment = audio_clip.subclipped(start_time, end_time)
            
            video_clip = image_clip.with_audio(audio_segment)
            section_clips.append(video_clip)
            
        if section_clips:
            section_video = concatenate_videoclips(section_clips)
            image_clips.append(section_video)
    
    if image_clips:
        final_clip = concatenate_videoclips(image_clips)
        
        final_clip.write_videofile(
            output_path, 
            fps=24,
            audio_codec='aac',
            audio=True
        )
        
        return output_path
    else:
        print("No video clips were created")
        return None


class DuckDuckGoSearchTool:
    def __init__(self):
        # Initialize search tool and session
        self.session = HTMLSession()
        self.search = DuckDuckGoSearchResults()

    def extract_urls(self, text: str) -> List[str]:
        """Extract URLs from the results of the LangChain duck duck go search tool."""
        url_pattern = r'https?://[^\s,]+'
        urls = re.findall(url_pattern, text)
        return urls

    def scrape_and_clean(self, url: str) -> str:
        """Scrape and clean text content from a given URL. Doesn't always work well with javascript websites."""
        try:
            response = self.session.get(url)
            soup = BeautifulSoup(response.content, 'html.parser')
            text = soup.get_text(separator=' ')
            return text
        except Exception as e:
            print(f"Failed to scrape URL {url}: {e}")
            return None

    def return_search_results(self, query: str, num_results: int=5) -> List[str]:
        """Perform a search query and return scraped content."""
        print(f'Performing Search on Query: {query} ...')

        # Perform a search query
        results = self.search.invoke(query, num_results=num_results)

        # Extract URLs from the search results
        urls = self.extract_urls(results)

        # Scrape and clean content for each URL
        scraped_content = []
        for url in urls:
            content = self.scrape_and_clean(url)
            if content:
                scraped_content.append(content)
            break

        print(f'...Done Performing Search on Query: {query}')
        return scraped_content

